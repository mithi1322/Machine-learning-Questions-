{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ecae79-2d53-4ee3-b8aa-bfaf73c7644b",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5d0ed-35e8-44dc-9dec-fd6d5d90d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "Overfitting and underfitting are common problems in machine learning. Overfitting occurs when a model is too complex and fits the training data too closely, \n",
    "resulting in poor generalization to new, unseen data. Underfitting, on the other hand, occurs when a model is too simple and cannot capture the underlying patterns in the data, \n",
    "resulting in poor performance on both the training and test sets. The consequences of overfitting include poor generalization performance, high variance, and high complexity, \n",
    "while the consequences of underfitting include high bias and low complexity. To mitigate overfitting, one can use techniques such as regularization, early stopping, and cross-validation. \n",
    "Underfitting can be addressed by using more complex models, adding more features, or collecting more data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7e044-2adf-435d-9f8d-40f7da100673",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3f0e5-d2ea-4637-9b3d-634b0a59ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "One can reduce overfitting by using techniques such as regularization, which adds a penalty term to the loss function to discourage over-reliance on certain features or weights; \n",
    "early stopping, which stops the training process when the validation error starts to increase; and data augmentation, which artificially increases the size of the training data set. \n",
    "Other methods include dropout, which randomly drops out certain neurons during training to prevent over-reliance on specific features, and ensemble methods, which combine multiple models to reduce overfitting.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b24fd-9e3e-42a1-b332-bcf87a40f499",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f78e2-6975-4431-b259-514eb9e48ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    " Underfitting occurs when a model is too simple and cannot capture the underlying patterns in the data, resulting in poor performance on both the training and test sets. \n",
    " It can occur when there is not enough data available for training, when the model is too simple or constrained, or when the data is noisy or contains outliers.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f248892-f458-4b4b-9644-5abd6af476d1",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c928995-74c6-4469-bbc8-71e3b9bf42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    " The bias-variance tradeoff is a fundamental concept in machine learning that refers to the tradeoff between the complexity of a model and its ability to generalize to new, unseen data. \n",
    " Bias refers to the difference between the expected predictions of the model and the true values, while variance refers to the variability of the model's predictions for different training sets. \n",
    " High bias models are typically too simple and cannot capture the underlying patterns in the data, while high variance models are too complex and overfit the training data. \n",
    " The goal of a good machine learning model is to find a balance between bias and variance that results in good generalization performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd23d90-4c23-4124-a2e9-4cf94009baae",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bb333-08f2-4425-b8ab-521d0c17ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "Common methods for detecting overfitting and underfitting include examining the training and validation error curves, using cross-validation to estimate model performance on new data,\n",
    "and comparing the training and test accuracy scores. Overfitting can be detected when the validation error starts to increase, while underfitting can be detected \n",
    "when the model has low training and validation accuracy scores. One can also use techniques such as learning curves, which plot the training and validation error as a \n",
    "function of the amount of training data, to diagnose overfitting and underfitting.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d5c30-fa0f-44e2-93af-117e19c6eec8",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fe8b5-fd41-416c-9988-aab6c934e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "Bias and variance are two important concepts in machine learning that refer to the tradeoff between model complexity and generalization performance. \n",
    "High bias models are typically too simple and have low capacity to capture the underlying patterns in the data, resulting in poor performance on both the training and test sets.\n",
    "High variance models, on the other hand, are too complex and overfit the training data, resulting in good performance on the training set but poor performance on the test set. \n",
    "Examples of high bias models include linear regression and logistic regression, while examples of high variance models include decision trees, random forests, and deep neural networks.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838bd58-f3df-41cb-8c70-108dbd8e6415",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad94e63-0ec3-4f00-8868-44a13b9e1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:\n",
    "'''\n",
    "Regularization is a technique in machine learning that is used to prevent overfitting by adding a penalty term to the loss function of a model. \n",
    "The penalty term encourages the model to learn simpler patterns that are more generalizable, rather than memorizing the training data.\n",
    "\n",
    "There are several common regularization techniques:\n",
    "\n",
    "1. L1 regularization: This technique adds a penalty proportional to the absolute value of the model parameters to the loss function. \n",
    "                      It encourages the model to learn sparse patterns by shrinking some of the model parameters to zero.\n",
    "\n",
    "2. L2 regularization: This technique adds a penalty proportional to the square of the model parameters to the loss function. \n",
    "                      It encourages the model to learn small patterns by shrinking all of the model parameters towards zero.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df703457-b399-4540-9ad8-40cd15d775e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
